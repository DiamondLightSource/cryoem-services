from __future__ import annotations

from typing import Optional

import numpy as np
import pytest

from cryoemservices.util.clem_array_functions import (
    convert_array_dtype,
    estimate_int_dtype,
    get_dtype_info,
    get_valid_dtypes,
)

known_dtypes = (
    "int8",
    "int16",
    "int32",
    "int64",
    "uint8",
    "uint16",
    "uint32",
    "uint64",
    "float16",
    "float32",
    "float64",
    "float128",
    "complex64",
    "complex128",
    "complex256",
)


def test_get_valid_dtypes():
    # All known dtypes should be generated by the function
    assert len(set(known_dtypes) - set(get_valid_dtypes())) == 0


@pytest.mark.parametrize("dtype", known_dtypes)
def test_get_dtype_info(dtype: str):

    # Load dtype info from NumPy
    dtype_info = (
        np.iinfo(dtype) if dtype.startswith(("int", "uint")) else np.finfo(dtype)
    )
    # Load dtype info via function
    dtype_func = get_dtype_info(dtype)

    # Compare the contents of the two objects
    assert (
        len(
            {dtype_info.min, dtype_info.max, str(dtype_info.dtype)}
            - {dtype_func.min, dtype_func.max, str(dtype_func.dtype)}
        )
        == 0
    )


dtype_estimation_test_matrix = (
    # Min value | Max value | Bit depth (optional) | As float? (bool) | Expected estimate
    # Test bit depth parameter
    (-128, 127, 8, True, "int8"),
    (0, 127, 16, False, "uint16"),
    (0, 127, 32, True, "uint32"),
    (-128, 127, 64, False, "int64"),
    # Test auto-find ability
    (0, 127, None, False, "uint8"),
    (-32768, 32767, None, True, "int16"),
    (-2147483648, 2147483647, None, False, "int32"),
    (0, 9223372036854775807, None, True, "uint64"),
)


@pytest.mark.parametrize("test_params", dtype_estimation_test_matrix)
def test_estimate_int_dtype(test_params: tuple[int, int, Optional[int], bool, str]):
    vmin, vmax, bits, is_float, target = test_params

    # Create test array
    shape = (32, 32)
    dtype = "float64" if is_float is True else "int64"
    arr = np.random.randint(vmin, vmax, shape).astype(dtype)

    estimate = estimate_int_dtype(arr, bits)
    assert estimate == target


array_conversion_test_matrix = (
    # Starting dtype | Target dtype | Estimate initial dtype?
    # Float -> int/uint
    ("float64", "int8", True),
    ("float32", "int16", False),
    ("float64", "int32", False),
    ("float32", "int64", True),
    ("float32", "uint8", False),
    ("float64", "uint16", True),
    ("float32", "uint32", True),
    ("float64", "uint64", False),
    # int -> int/uint
    ("int64", "int8", False),
    ("int32", "int16", True),
    ("int16", "int32", False),
    ("int8", "int64", True),
    ("int32", "uint8", True),
    ("int64", "uint16", False),
    ("int8", "uint32", True),
    ("int16", "uint64", False),
    # uint -> int/uint
    ("uint32", "int8", True),
    ("uint64", "int16", False),
    ("uint8", "int32", True),
    ("uint16", "int64", False),
    ("uint64", "uint8", False),
    ("uint32", "uint16", True),
    ("uint16", "uint32", False),
    ("uint8", "uint64", True),
)


@pytest.mark.parametrize("test_params", array_conversion_test_matrix)
def test_convert_array_dtype(test_params: tuple[str, str, bool]):

    def normalize(arr: np.ndarray) -> np.ndarray:
        diff = arr.max() - arr.min()
        return (arr / diff) - (arr.min() / diff)

    # Get dtype parameters
    dtype_0, dtype_1, estimate = test_params
    info_0 = get_dtype_info(dtype_0)
    info_1 = get_dtype_info(dtype_1)
    shape = (16, 16)

    if dtype_0.startswith(("int", "uint")):
        # Use half range of starting array
        # (np.random.randint uses "int64" by default, so "uint64"'s max value will
        # exceed it)
        vmin = int(0.5 * info_0.min)
        vmax = int(0.5 * info_0.max)
        arr_0 = np.random.randint(vmin, vmax, size=shape).astype(dtype_0)
    else:
        # Use half the integer range of target dtype if starting with float
        vmin = int(0.5 * info_1.min)
        vmax = int(0.5 * info_1.max)
        arr_0 = np.random.randint(vmin, vmax, size=shape).astype(dtype_0)

    # Convert the array using the function
    initial_dtype = estimate_int_dtype(arr_0) if estimate is True else None
    arr_1 = convert_array_dtype(arr_0, dtype_1, initial_dtype)

    # Normalise both arrays to (0, 1) for comparison
    arr_0 = normalize(arr_0)
    arr_1 = normalize(arr_1)

    # Check that deviations are within a set threshold:
    # arr_1 - arr_0 = atol + rtol * abs(arr_0)
    np.testing.assert_allclose(
        arr_1,
        arr_0,
        rtol=0,
        atol=0.01,  # <= 1% deviation when going between 64- and 8-bit arrays
    )


def test_stretch_image_contrast():
    pass


def test_convert_to_rgb():
    pass


image_flattening_test_matrix = (
    # Dimensions | Values | Flattening mode | Is float? | Expected value
    # Simulate grayscale images
    (3, (i for i in range(3)), "mean", True, 1),
    (3, (i for i in range(3)), "min", False, 0),
    (3, (i for i in range(3)), "max", True, 2),
    # Simulate coloured images
    (4, (i for i in range(3)), "mean", True, (0, 1, 2)),
    (4, (i for i in range(3)), "min", False, (0, 1, 2)),
    (4, (i for i in range(3)), "max", True, (0, 1, 2)),
)


def test_flatten_image():
    pass


def test_merge_images():
    pass


def test_preprocess_img_stk():
    pass


def test_write_stack_to_tiff():
    pass
